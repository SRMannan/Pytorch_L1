{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNh2xvHunn8OdzmQjf97G1O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SRMannan/Pytorch_L1/blob/main/5_NN_Module.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **torch.nn Module in PyTorch**\n",
        "\n",
        "The `torch.nn` module in PyTorch is a core library that provides a wide array of classes and functions designed to help developers build neural networks efficiently and effectively. It abstracts the complexity of creating and training neural networks by offering pre-built layers, loss functions, activation functions, and other utilities, enabling you to focus on designing and experimenting with model architectures.\n",
        "\n",
        "---\n",
        "\n",
        "## **Key Components of `torch.nn`:**\n",
        "\n",
        "### **1. Modules (Layers):**\n",
        "- **`nn.Module`**: The base class for all neural network modules. Your custom models and layers should subclass this class.\n",
        "- **Common Layers**:\n",
        "  - `nn.Linear`: Fully connected layer.\n",
        "  - `nn.Conv2d`: Convolutional layer.\n",
        "  - `nn.LSTM`: Recurrent layer.\n",
        "  - Many more layers are available for different use cases.\n",
        "\n",
        "---\n",
        "\n",
        "### **2. Activation Functions:**\n",
        "- Introduce non-linearities to the model, allowing it to learn complex patterns.\n",
        "- Examples:\n",
        "  - `nn.ReLU`: Rectified Linear Unit.\n",
        "  - `nn.Sigmoid`: Sigmoid activation function.\n",
        "  - `nn.Tanh`: Hyperbolic tangent function.\n",
        "\n",
        "---\n",
        "\n",
        "### **3. Loss Functions:**\n",
        "- Quantify the difference between the model's predictions and the actual targets.\n",
        "- Examples:\n",
        "  - `nn.CrossEntropyLoss`: For classification tasks.\n",
        "  - `nn.MSELoss`: Mean Squared Error Loss.\n",
        "  - `nn.NLLLoss`: Negative Log Likelihood Loss.\n",
        "\n",
        "---\n",
        "\n",
        "### **4. Container Modules:**\n",
        "- **`nn.Sequential`**:\n",
        "  - A sequential container to stack layers in order.\n",
        "  - Example:\n",
        "    ```python\n",
        "    model = nn.Sequential(\n",
        "        nn.Linear(10, 50),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(50, 1)\n",
        "    )\n",
        "    ```\n",
        "\n",
        "---\n",
        "\n",
        "### **5. Regularization and Dropout:**\n",
        "- Helps prevent overfitting and improves the model's ability to generalize to new data.\n",
        "- Examples:\n",
        "  - `nn.Dropout`: Randomly zeroes some of the elements of the input tensor during training.\n",
        "  - `nn.BatchNorm2d`: Batch normalization for 2D input, normalizing layer activations.\n",
        "\n",
        "---\n",
        "\n",
        "**Note**: PyTorch's `torch.nn` module, when combined with `torch.optim` and `torch.autograd`, provides a powerful toolkit for creating, training, and fine-tuning neural networks.\n",
        "\n"
      ],
      "metadata": {
        "id": "aJ83rx86bMpr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "wNqth1FWaeRu"
      },
      "outputs": [],
      "source": [
        " import torch\n",
        " import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#create model class\n",
        "class Model(nn.Module):\n",
        "  def __init__(self , num_features):\n",
        "\n",
        "    #invocking const of parent class\n",
        "    super().__init__()\n",
        "    self.linear = nn.Linear(num_features , 1)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "  def forward(self , features):\n",
        "    out = self.linear(features)\n",
        "    out = self.sigmoid(out)\n",
        "    return out"
      ],
      "metadata": {
        "id": "aNVhPmXYbvAO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##for simplicity we are making our own dataset\n",
        "features = torch.rand(10,5)\n",
        "\n",
        "model = Model(features.shape[1])\n",
        "\n",
        "model(features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AivPhChxcAak",
        "outputId": "7918148b-231b-4890-dd8a-eca97a459148"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.7108],\n",
              "        [0.6083],\n",
              "        [0.6163],\n",
              "        [0.7298],\n",
              "        [0.6235],\n",
              "        [0.6416],\n",
              "        [0.7315],\n",
              "        [0.6912],\n",
              "        [0.6893],\n",
              "        [0.6772]], grad_fn=<SigmoidBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.linear.weight"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v527rSopcAdJ",
        "outputId": "1c4912e7-266c-4254-fe98-0cf599d08ebe"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[ 0.1528,  0.2312, -0.3200,  0.0050,  0.1196]], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.linear.bias"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYrMh9DZcAft",
        "outputId": "1bbda188-5373-4ca8-ea95-df36c3c4f890"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([0.0899], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Re8OKmiwbvCw",
        "outputId": "b328fcc7-aac4-4cca-f9c6-63694e2e6a1d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchinfo import summary\n",
        "\n",
        "summary(model , input_size = (10,5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_JP08uad_62",
        "outputId": "c6c02f3a-39ac-4057-f89c-8bea25a98101"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "Model                                    [10, 1]                   --\n",
              "├─Linear: 1-1                            [10, 1]                   6\n",
              "├─Sigmoid: 1-2                           [10, 1]                   --\n",
              "==========================================================================================\n",
              "Total params: 6\n",
              "Trainable params: 6\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (Units.MEGABYTES): 0.00\n",
              "==========================================================================================\n",
              "Input size (MB): 0.00\n",
              "Forward/backward pass size (MB): 0.00\n",
              "Params size (MB): 0.00\n",
              "Estimated Total Size (MB): 0.00\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Neural Network Architecture\n",
        "\n",
        "1. **Input Layer**:\n",
        "   - Contains **5 features** as input.\n",
        "\n",
        "2. **Hidden Layer**:\n",
        "   - **3 neurons** in the hidden layer.\n",
        "   - Activation function: **ReLU**.\n",
        "\n",
        "3. **Output Layer**:\n",
        "   - **1 neuron** for binary classification.\n",
        "   - Activation function: **Sigmoid**.\n",
        "\n",
        "**Summary:**\n",
        "- Input → Hidden Layer (3 neurons, ReLU) → Output Layer (1 neuron, Sigmoid)\n"
      ],
      "metadata": {
        "id": "UvwfWiUhiFJs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, no_of_features):\n",
        "        super().__init__()\n",
        "        self.Linear1 = nn.Linear(no_of_features, 3)  # Adjusted input size to be dynamic\n",
        "        self.relu = nn.ReLU()\n",
        "        self.Linear2 = nn.Linear(3, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, no_of_features):\n",
        "        out = self.Linear1(no_of_features)\n",
        "        out = self.relu(out)\n",
        "        out = self.Linear2(out)\n",
        "        out = self.sigmoid(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "gF5qIdxAd_9V"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = torch.rand(10,5)\n",
        "\n",
        "model = Model(features.shape[1])\n",
        "\n",
        "model(features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsnK2bKyd__5",
        "outputId": "7a9cd21b-ee36-47fc-d679-9defe11e0b21"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.3665],\n",
              "        [0.3459],\n",
              "        [0.3723],\n",
              "        [0.3477],\n",
              "        [0.3764],\n",
              "        [0.3681],\n",
              "        [0.3571],\n",
              "        [0.3658],\n",
              "        [0.3510],\n",
              "        [0.3485]], grad_fn=<SigmoidBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sequential Containers in PyTorch\n",
        "\n",
        "## Overview\n",
        "In PyTorch, **Sequential** is a container module used to define a neural network layer by layer in a linear manner. It allows the user to stack layers and operations without explicitly defining a `forward()` method. It is particularly useful when creating simple models where layers are applied in sequence, and there are no complex branchings.\n",
        "\n",
        "## Key Points\n",
        "- **Definition**: `nn.Sequential` is a container that allows the layers or operations to be added sequentially.\n",
        "- **Layer Stack**: Layers are stacked in the order they are defined and are executed in the same order during the forward pass.\n",
        "- **Simplification**: It simplifies model construction by eliminating the need to manually define the forward pass for models with a simple structure.\n",
        "\n",
        "## Syntax\n",
        "```python\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(in_features, out_features),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(out_features, 1),\n",
        "    nn.Sigmoid()\n",
        ")\n"
      ],
      "metadata": {
        "id": "FEis_Pu0kpyp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "  def __init__(self , no_of_features):\n",
        "    super().__init__()\n",
        "    self.network = nn.Sequential(\n",
        "        nn.Linear(no_of_features , 3),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(3,1),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "\n",
        "  def forward(self , no_of_features):\n",
        "    out = self.network(no_of_features)\n",
        "    return out"
      ],
      "metadata": {
        "id": "CrG6-ebNkp5W"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = torch.rand(10,5)\n",
        "\n",
        "model = Model(features.shape[1])\n",
        "\n",
        "model(features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ArL77Zd1loHB",
        "outputId": "97df882f-9075-46ac-ffc0-98e203c1d957"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.5186],\n",
              "        [0.5307],\n",
              "        [0.5323],\n",
              "        [0.5253],\n",
              "        [0.5341],\n",
              "        [0.5317],\n",
              "        [0.5241],\n",
              "        [0.5439],\n",
              "        [0.5263],\n",
              "        [0.5260]], grad_fn=<SigmoidBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    }
  ]
}
